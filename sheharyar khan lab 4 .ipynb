{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f72d48-5cee-4ab8-8213-edd36953e703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Age:  [2 2 0 0 1 1]\n",
      "Encoded Income:  [1 0 1 0 1 0]\n",
      "Encoded Outlook:  [0 1 0 1 0 1]\n",
      "Encoded Play:  [0 1 1 1 0 0]\n",
      "Predictions: [0 0]\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "data = {\n",
    "    'Age': ['Youth', 'Youth', 'Medium', 'Medium', 'Senior', 'Senior'],\n",
    "    'Income': ['Low', 'High', 'Low', 'High', 'Low', 'High'],\n",
    "    'Outlook': ['Fair', 'Good', 'Fair', 'Good', 'Fair', 'Good'],\n",
    "    'Play': ['No', 'Yes', 'Yes', 'Yes', 'No', 'No']\n",
    "}\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "age_encoded = le.fit_transform(data['Age'])\n",
    "income_encoded = le.fit_transform(data['Income'])\n",
    "outlook_encoded = le.fit_transform(data['Outlook'])\n",
    "\n",
    "play_encoded = le.fit_transform(data['Play'])\n",
    "\n",
    "print(\"Encoded Age: \", age_encoded)\n",
    "print(\"Encoded Income: \",income_encoded)\n",
    "print(\"Encoded Outlook: \",outlook_encoded)\n",
    "print(\"Encoded Play: \", play_encoded)\n",
    "\n",
    "features = list(zip(age_encoded,income_encoded, outlook_encoded))\n",
    "\n",
    "features_train, features_test, label_train, label_test = train_test_split(features, play_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(features_train, label_train)\n",
    "\n",
    "predicted = model.predict(features_test)\n",
    "print(f\"Predictions: {predicted}\")\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(label_test, predicted)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "accuracy = accuracy_score(label_test, predicted)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "new_data = [[1, 1, 0]]  # Example: Medium = 1, High = 1, Fair = 0\n",
    "new_prediction = model.predict(new_data)\n",
    "new_prediction_label = le.inverse_transform(new_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bdf28-16cb-4022-b6e9-9d0e176c58cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da2ade-97c1-44b7-9c44-9c97b39e18a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aad5bd-d502-4475-bebb-cb6e4b361a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9750f7bc-2c93-4ef4-922f-cb37bf712f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 0 1]\n",
      "Confusion Matrix:\n",
      "[[0 1]\n",
      " [1 1]]\n",
      "Accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "age = ['youth','youth','middle_aged','senior','senior','senior','middle_aged','youth','youth','senoir','youth','middle_aged','middle_aged','senior']\n",
    "income = ['high','high','high','medium','low','low','low','medium','low','medium','medium','medium','high','medium']\n",
    "student = ['no','no','no','no','yes','yes','yes','no','yes','yes','yes','no','yes','no']\n",
    "credit_rating = ['fair','excellent','fair','fair','fair','excellent','excellent','fair','fair','fair','excellent','excellent','fair','excelent']\n",
    "buys_comp = ['no','no','yes','yes','yes','no','yes','no','yes','yes','yes','yes','yes','no']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "age_encoded = le.fit_transform(age)\n",
    "income_encoded = le.fit_transform(income)\n",
    "student_encoded = le.fit_transform(student)\n",
    "credit_rating_encoded = le.fit_transform(credit_rating)\n",
    "buys_comp_encoded = le.fit_transform(buys_comp)\n",
    "\n",
    "\n",
    "features = list(zip(age_encoded,income_encoded,student_encoded,credit_rating_encoded))\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test,label_train,label_test=train_test_split(features, buys_comp_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(features_train, label_train)\n",
    "predicted = model.predict(features_test)\n",
    "print(\"Prediction:\", predicted)\n",
    "conf_mat = confusion_matrix(label_test, predicted)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "accuracy = accuracy_score(label_test, predicted)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc8cda0-5acd-4c99-aeab-aa87bbb18ead",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'karachi_real_estate_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, mean_squared_error\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkarachi_real_estate_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Drop columns that have all missing values\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'karachi_real_estate_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"karachi_real_estate_data.csv\")\n",
    "\n",
    "# Drop columns that have all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove any column with \"Unnamed\" in its name if it’s unnecessary\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Keep a copy of the original feature columns\n",
    "X_original = df.drop(columns=['Price ($)'])  # Features without the target column\n",
    "\n",
    "# Preprocessing steps\n",
    "X = X_original.copy()  # Keep the original DataFrame for column names\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Handle missing values by imputing them with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)  # The imputed version of X\n",
    "\n",
    "# Keep column names after imputation\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate Mean Squared Error for model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Select the last 20 entries and show predictions along with the features\n",
    "X_pred = X_imputed[-20:]\n",
    "y_pred_last_20 = model.predict(X_pred)\n",
    "\n",
    "# Display the predictions along with the original features\n",
    "predictions_df = X_original[-20:].copy()  # Select the last 20 rows of the original data\n",
    "predictions_df['Predicted Price Category'] = y_pred_last_20\n",
    "\n",
    "print(\"Predictions for the last 20 entries with original features:\")\n",
    "print(predictions_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d2a73a5-13f6-4647-87f9-74f1f7108720",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m X_imputed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_imputed, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_imputed, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the Naive Bayes model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m GaussianNB()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"karachi_real_estate_data.csv\")\n",
    "\n",
    "# Drop columns that have all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove any column with \"Unnamed\" in its name if it’s unnecessary\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Keep a copy of the original feature columns\n",
    "X_original = df.drop(columns=['Price ($)'])  # Features without the target column\n",
    "\n",
    "# Preprocessing steps\n",
    "X = X_original.copy()  # Keep the original DataFrame for column names\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Handle missing values by imputing them with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)  # The imputed version of X\n",
    "\n",
    "# Keep column names after imputation\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate Mean Squared Error for model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Select the last 20 entries and show predictions along with the features\n",
    "X_pred = X_imputed[-20:]\n",
    "y_pred_last_20 = model.predict(X_pred)\n",
    "\n",
    "# Display the predictions along with the original features\n",
    "predictions_df = X_original[-20:].copy()  # Select the last 20 rows of the original data\n",
    "predictions_df['Predicted Price Category'] = y_pred_last_20\n",
    "\n",
    "print(\"Predictions for the last 20 entries with original features:\")\n",
    "print(predictions_df) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385c07c2-5704-4290-8629-67f3de474879",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m X_imputed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_imputed, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_imputed, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the Naive Bayes model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m GaussianNB()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"karachi_real_estate_data.csv\")\n",
    "\n",
    "# Drop columns that have all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove any column with \"Unnamed\" in its name if it’s unnecessary\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Keep a copy of the original feature columns\n",
    "X_original = df.drop(columns=['Price ($)'])  # Features without the target column\n",
    "\n",
    "# Preprocessing steps\n",
    "X = X_original.copy()  # Keep the original DataFrame for column names\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Handle missing values by imputing them with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)  # The imputed version of X\n",
    "\n",
    "# Keep column names after imputation\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate Mean Squared Error for model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Select the last 20 entries and show predictions along with the features\n",
    "X_pred = X_imputed[-20:]\n",
    "y_pred_last_20 = model.predict(X_pred)\n",
    "\n",
    "# Display the predictions along with the original features\n",
    "predictions_df = X_original[-20:].copy()  # Select the last 20 rows of the original data\n",
    "predictions_df['Predicted Price Category'] = y_pred_last_20\n",
    "\n",
    "print(\"Predictions for the last 20 entries with original features:\")\n",
    "print(predictions_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29f6810-8f62-42de-b2ea-b1bc5bcb21b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4.55%\n",
      "Confusion Matrix:\n",
      "[[0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 0]\n",
      " [0 0 0 0 0 1 1 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 2 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 1 2 0 6 1 0]]\n",
      "Mean Squared Error: 42500000000.0\n",
      "Predictions for the last 20 entries with original features:\n",
      "     House ID             Location  Size (sq ft)  Bedrooms  Bathrooms  \\\n",
      "90       4091          DHA Phase 4          1200         2          4   \n",
      "91       4092        North Karachi          1500         3          1   \n",
      "92       4093      Clifton Block 5          1800         4          2   \n",
      "93       4094    Gulistan-e-Jauhar          2100         5          3   \n",
      "94       4095          DHA Phase 8           900         1          4   \n",
      "95       4096        PECHS Block 6          1200         2          1   \n",
      "96       4097          Garden West          1500         3          2   \n",
      "97       4098  Malir Cantt Block 1          1800         4          3   \n",
      "98       4099      Gulshan Block 4          2100         5          4   \n",
      "99       4100          DHA Phase 2           900         1          1   \n",
      "100      4101              Korangi          1200         2          2   \n",
      "101      4102          Liaquatabad          1500         3          3   \n",
      "102      4103      Clifton Block 7          1800         4          4   \n",
      "103      4104     Gulshan-e-Maymar          2100         5          1   \n",
      "104      4105               Saddar           900         1          2   \n",
      "105      4106            F.B. Area          1200         2          3   \n",
      "106      4107      Clifton Block 2          1500         3          4   \n",
      "107      4108      Gulshan Block 3          1800         4          1   \n",
      "108      4109          DHA Phase 6          2100         5          2   \n",
      "109      4110      Gulshan Block 5           900         1          3   \n",
      "\n",
      "     Year Built  Condition Rating  Distance to City Center (km)  \\\n",
      "90         2016                 2                             4   \n",
      "91         2017                 3                             5   \n",
      "92         2018                 4                             6   \n",
      "93         2019                 5                             7   \n",
      "94         2020                 1                             8   \n",
      "95         2005                 2                             9   \n",
      "96         2006                 3                            10   \n",
      "97         2007                 4                            11   \n",
      "98         2008                 5                            12   \n",
      "99         2009                 1                             3   \n",
      "100        2010                 2                             4   \n",
      "101        2011                 3                             5   \n",
      "102        2012                 4                             6   \n",
      "103        2013                 5                             7   \n",
      "104        2014                 1                             8   \n",
      "105        2015                 2                             9   \n",
      "106        2016                 3                            10   \n",
      "107        2017                 4                            11   \n",
      "108        2018                 5                            12   \n",
      "109        2019                 1                             3   \n",
      "\n",
      "     Property Type  Predicted Price Category  \n",
      "90           Villa                    350000  \n",
      "91       Apartment                    650000  \n",
      "92   Single Family                    550000  \n",
      "93       Townhouse                    550000  \n",
      "94           Villa                    350000  \n",
      "95       Apartment                    650000  \n",
      "96   Single Family                    450000  \n",
      "97       Townhouse                    650000  \n",
      "98           Villa                    550000  \n",
      "99       Apartment                    450000  \n",
      "100  Single Family                    650000  \n",
      "101      Townhouse                    650000  \n",
      "102          Villa                    550000  \n",
      "103      Apartment                    650000  \n",
      "104  Single Family                    650000  \n",
      "105      Townhouse                    550000  \n",
      "106          Villa                    550000  \n",
      "107      Apartment                    650000  \n",
      "108  Single Family                    550000  \n",
      "109      Townhouse                    350000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"karachi_real_estate_data.csv\")\n",
    "\n",
    "# Drop columns that have all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove any column with \"Unnamed\" in its name if it’s unnecessary\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Define the target variable and feature columns\n",
    "y = df['Price ($)']  # Target variable\n",
    "X_original = df.drop(columns=['Price ($)'])  # Features without the target column\n",
    "\n",
    "# Preprocessing steps\n",
    "X = X_original.copy()  # Keep the original DataFrame for column names\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Handle missing values by imputing them with the median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)  # The imputed version of X\n",
    "\n",
    "# Keep column names after imputation\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate Mean Squared Error for model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Select the last 20 entries and show predictions along with the features\n",
    "X_pred = X_imputed[-20:]\n",
    "y_pred_last_20 = model.predict(X_pred)\n",
    "\n",
    "# Display the predictions along with the original features\n",
    "predictions_df = X_original[-20:].copy()  # Select the last 20 rows of the original data\n",
    "predictions_df['Predicted Price Category'] = y_pred_last_20\n",
    "\n",
    "print(\"Predictions for the last 20 entries with original features:\")\n",
    "print(predictions_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224554f5-f8cc-4877-a4a0-2c9c2e38e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.64%\n",
      "Confusion Matrix:\n",
      " [[5 3]\n",
      " [5 9]]\n",
      "Mean Squared Error: 0.36363636363636365\n",
      "Predictions for the last 20 entries with all columns:\n",
      "      House ID  Location  Size (sq ft)  Bedrooms  Bathrooms  Year Built  \\\n",
      "90     4091.0       6.0        1200.0       2.0        4.0      2016.0   \n",
      "91     4092.0      25.0        1500.0       3.0        1.0      2017.0   \n",
      "92     4093.0       3.0        1800.0       4.0        2.0      2018.0   \n",
      "93     4094.0      13.0        2100.0       5.0        3.0      2019.0   \n",
      "94     4095.0       9.0         900.0       1.0        4.0      2020.0   \n",
      "95     4096.0      28.0        1200.0       2.0        1.0      2005.0   \n",
      "96     4097.0      12.0        1500.0       3.0        2.0      2006.0   \n",
      "97     4098.0      23.0        1800.0       4.0        3.0      2007.0   \n",
      "98     4099.0      16.0        2100.0       5.0        4.0      2008.0   \n",
      "99     4100.0       5.0         900.0       1.0        1.0      2009.0   \n",
      "100    4101.0      20.0        1200.0       2.0        2.0      2010.0   \n",
      "101    4102.0      21.0        1500.0       3.0        3.0      2011.0   \n",
      "102    4103.0       4.0        1800.0       4.0        4.0      2012.0   \n",
      "103    4104.0      19.0        2100.0       5.0        1.0      2013.0   \n",
      "104    4105.0      29.0         900.0       1.0        2.0      2014.0   \n",
      "105    4106.0      10.0        1200.0       2.0        3.0      2015.0   \n",
      "106    4107.0       2.0        1500.0       3.0        4.0      2016.0   \n",
      "107    4108.0      15.0        1800.0       4.0        1.0      2017.0   \n",
      "108    4109.0       8.0        2100.0       5.0        2.0      2018.0   \n",
      "109    4110.0      17.0         900.0       1.0        3.0      2019.0   \n",
      "\n",
      "     Condition Rating  Distance to City Center (km)  Property Type  \\\n",
      "90                2.0                           4.0            3.0   \n",
      "91                3.0                           5.0            0.0   \n",
      "92                4.0                           6.0            1.0   \n",
      "93                5.0                           7.0            2.0   \n",
      "94                1.0                           8.0            3.0   \n",
      "95                2.0                           9.0            0.0   \n",
      "96                3.0                          10.0            1.0   \n",
      "97                4.0                          11.0            2.0   \n",
      "98                5.0                          12.0            3.0   \n",
      "99                1.0                           3.0            0.0   \n",
      "100               2.0                           4.0            1.0   \n",
      "101               3.0                           5.0            2.0   \n",
      "102               4.0                           6.0            3.0   \n",
      "103               5.0                           7.0            0.0   \n",
      "104               1.0                           8.0            1.0   \n",
      "105               2.0                           9.0            2.0   \n",
      "106               3.0                          10.0            3.0   \n",
      "107               4.0                          11.0            0.0   \n",
      "108               5.0                          12.0            1.0   \n",
      "109               1.0                           3.0            2.0   \n",
      "\n",
      "     Predicted Price Category  \n",
      "90                          1  \n",
      "91                          0  \n",
      "92                          1  \n",
      "93                          1  \n",
      "94                          1  \n",
      "95                          0  \n",
      "96                          0  \n",
      "97                          1  \n",
      "98                          1  \n",
      "99                          0  \n",
      "100                         0  \n",
      "101                         0  \n",
      "102                         1  \n",
      "103                         0  \n",
      "104                         0  \n",
      "105                         1  \n",
      "106                         1  \n",
      "107                         0  \n",
      "108                         1  \n",
      "109                         0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"karachi_real_estate_data.csv\")\n",
    "\n",
    "# Drop columns with all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Remove any unnecessary \"Unnamed\" columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Price ($)'])  # Assuming 'Price ($)' is the target\n",
    "y = df['Price ($)']\n",
    "\n",
    "# Experiment with binning: Adjust bins based on the distribution of Price ($)\n",
    "y = pd.cut(y, bins=3, labels=False)  # Start with 3 bins, adjust based on distribution\n",
    "\n",
    "# Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)  # Keep as DataFrame\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model (try CategoricalNB if data is mainly categorical)\n",
    "model = GaussianNB()  # Switch to CategoricalNB() if mostly categorical\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Display predictions for the last 20 entries with all columns\n",
    "X_pred_last_20 = X[-20:].copy()  # Select the last 20 entries\n",
    "y_pred_last_20 = model.predict(X_pred_last_20)  # Make predictions\n",
    "\n",
    "# Add the predictions as a new column\n",
    "X_pred_last_20['Predicted Price Category'] = y_pred_last_20\n",
    "\n",
    "print(\"Predictions for the last 20 entries with all columns:\\n\", X_pred_last_20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f6e59-854f-498f-bb9c-bcc659cc448e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
